{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21587dae",
   "metadata": {},
   "source": [
    "### Question 3: Count records\n",
    "\n",
    "How many taxi trips were there on the 15th of October?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ee06c62-5140-427e-a49e-6e48d5bbf224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession, types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d08c33a8-184a-4661-a9d9-74fc2460a4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/07 15:20:05 WARN Utils: Your hostname, SOLIDCAD-SERVER resolves to a loopback address: 127.0.1.1; using 192.168.160.37 instead (on interface eth0)\n",
      "25/03/07 15:20:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/07 15:20:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/03/07 15:20:09 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/03/07 15:20:09 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName('test') \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dad2472-bf27-4968-88f5-cbafeb3859d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "     .option(\"header\", \"true\") \\\n",
    "     .parquet('/home/myothet/repos/data-engineering/batch/yellow_tripdata_2024-10.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca2aab18-f3a3-419f-ba7d-4f58dbd3fb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('yellow_tripdata/2024/10', mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "defd49b9-3e3f-49fd-9193-83594853b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('yellow_tripdata/2024/10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c3cc1f0-b034-49f6-a7a5-afd747bdb8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3833771"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df5fdecb-825c-4781-9787-31ad20497ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e51d19-ba15-4abc-a469-6255673612f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e1f1fde-f5fc-4965-b9ef-87685acd993b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127993"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.tpep_pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df.tpep_dropoff_datetime)) \\\n",
    "    .filter(\"pickup_date = '2024-10-15'\") \\\n",
    "    .filter(\"dropoff_date = '2024-10-15'\") \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a2fec1e-bff6-441a-bf1a-2d1c8954534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.registerTempTable('yellow_tripdata_2024_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6992c4bb-90d1-436c-a311-da9c97ed09f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    COUNT(1)\n",
    "FROM \n",
    "    yellow_tripdata_2024_10\n",
    "WHERE\n",
    "    to_date(tpep_pickup_datetime) = '2024-10-15' AND\n",
    "    to_date(tpep_dropoff_datetime) = '2024-10-15';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4870183c-d334-4e24-b818-2440ba7ab070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  127993|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
